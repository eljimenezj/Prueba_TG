{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Entrega Prueba_TG_ELJ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMujjVXUB0f0TxIbdMq16wc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eljimenezj/Prueba_TG/blob/main/1.%20Entrega_Prueba_TG_ELJ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCSugbOehQIy"
      },
      "source": [
        "# Clasificación de imagenes utilizando Deep Learning - Una aplicación de Hand Signs\r\n",
        "\r\n",
        "En este libro se desarrolla toda la solución para una prueba tecnica que consiste en la creación de un modelo que permita realizar clasificación de imagenes, puntualmente imagenes con números del 0 al 5 representados con la mano humana. Este modelo es posteriormente desplegado en `streamlit` para que pueda ser utilizado por un usuario final.\r\n",
        "\r\n",
        "Finalmente, este desarrollo se presenta como parte de una prueba técnica de Trascender Global \r\n",
        "\r\n",
        "\r\n",
        "Presentado por\r\n",
        "\r\n",
        "* Edgar Leandro Jimenez Jaimes - eljimenezj@gmail.com\r\n",
        "\r\n",
        "Febrero 2021\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGTNxKsQkAVB"
      },
      "source": [
        "Este libro se encuentra organizado de la siguiente manera:\r\n",
        "\r\n",
        "1. Lectura y estructuración del pipeline de los datos.\r\n",
        "2. Estructuración del Data Augmentation utilizando ImageDataGenerator\r\n",
        "3. Entrenamiento de red neuronal preentrenada:ResNet50\r\n",
        "4. Graficas de desempeño\r\n",
        "5. Prueba de desempeño en los datos de testeo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLJTokRJhL4S"
      },
      "source": [
        "# Vamos a cargar las Librerias necesarias para preprocesar\r\n",
        "\r\n",
        "from PIL import Image\r\n",
        "import pandas as pd\r\n",
        "import glob\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "import imutils\r\n",
        "import time\r\n",
        "import os\r\n",
        "from google.colab import drive\r\n",
        "from google.colab import files\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "#import seaborn as sn  \r\n",
        "#import datetime\r\n",
        "#from tqdm import tqdm\r\n",
        "#from pathlib import Path\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import keras_preprocessing\r\n",
        "from keras.applications import densenet  \r\n",
        "from keras import regularizers  \r\n",
        "from keras import backend as K  \r\n",
        "from keras.preprocessing import image\r\n",
        "from keras.layers import Conv2D, MaxPooling2D\r\n",
        "from keras_preprocessing.image import ImageDataGenerator\r\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\r\n",
        "from keras.models import Sequential, Model, load_model  \r\n",
        "from keras.applications.resnet50 import preprocess_input \r\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint \r\n",
        "from keras.backend import manual_variable_initialization \r\n",
        "manual_variable_initialization(True)\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NupmzpW8tMHI"
      },
      "source": [
        "# 1. Lectura y estructuración del rutas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccs5Lb2ZGVkU",
        "outputId": "d5d42eca-15bb-42df-c62d-828dd9e64c77"
      },
      "source": [
        "'''\r\n",
        " Ahora realizamos la autenticacion necesaria para Google Drive\r\n",
        " e ir a buscar los datos almacenados, esto debe realizare cada vez\r\n",
        " que se reinicie el Colab \r\n",
        "'''\r\n",
        "\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DENS5IwsGjbJ"
      },
      "source": [
        "'''\r\n",
        " Definición de algunos parametros de entrada que serviran de control durante el notebook. Las variables\r\n",
        " img_width, img_height configuran el ancho y alto en pixeles que se van a tomar de las imagenes de entradas\r\n",
        " nb_train_samples se refiere al numero inicial de muestras en train, nb_validation_samples y nb_test_samples\r\n",
        " al numero de imagenes en validacion y test respectivamente. Y el batch_size será el encargado de controlar\r\n",
        " un numero de imagenes dado, es decir el valor configurado se refiere a un numero de imagenes\r\n",
        "'''\r\n",
        "\r\n",
        "img_width, img_height = 64, 64  \r\n",
        "nb_train_samples = 864             \r\n",
        "nb_validation_samples = 216        \r\n",
        "nb_test_samples = 120\r\n",
        "batch_size = 32                    \r\n",
        "\r\n",
        "\r\n",
        "'''\r\n",
        " Hacemos definición de los directorios donde se encuentra la información, estas imagenes se encuentran\r\n",
        " almacenadas por carpetas y divididas en las etiquetas de los numeros 1,2,3,4 y 5 respectivamente\r\n",
        "'''\r\n",
        "\r\n",
        "path_base = '/content/drive/My Drive/Prueba_Trascender/Datos'\r\n",
        "train_data_dir = path_base + '/train_signs'  \r\n",
        "validation_data_dir = path_base + '/val_signs'\r\n",
        "test_data_dir = path_base + '/test_signs'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc4MW5YfHmXs"
      },
      "source": [
        "# 2. Estructuración del Data Augmentation utilizando ImageDataGenerator\r\n",
        "A continuación se van a configurar los generadores de datos que nos van a servir para establecer los datos de entrenamiento, de validación y de testeo. Para esta tarea se utiliza `ImageDataGenerator` la cual una función creada en Keras que genera pilas de imágenes con datos crecientes en tiempo real."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ybyml87hP3I",
        "outputId": "55fafed5-9256-4a10-bc09-9ca5e7c073a5"
      },
      "source": [
        "\r\n",
        "'''\r\n",
        "Estructuramos el DataAugmentacion que se va a utilizar durante el entrenamiento de las imagenes para esto se utiliza \r\n",
        "ImageDataGenerator como se menciono anteriormente, la cual se configuro de la siguiente manera:\r\n",
        "\r\n",
        "--> horizontal_flip:  Ejecuta vueltas a las imagenes (efecto similar a un espejo)\r\n",
        "\r\n",
        "--> rotation_range: Rotaciónn de la imagen en el rango [0,90]\r\n",
        "\r\n",
        "--> brightness_range: Cambia los niveles de luminosidad de la imagen\r\n",
        "\r\n",
        "--> : Realiza Zoom a la imagen (Si < 1 acerco, = 1 Misma imagen, > 1 Alejo)\r\n",
        "\r\n",
        "'''\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "    preprocessing_function=preprocess_input,\r\n",
        "    horizontal_flip=True,                                        \r\n",
        "    rotation_range=90,                                           \r\n",
        "    brightness_range=[0.2,0.8],                                  \r\n",
        "    zoom_range=[0.8,1.2])                                        \r\n",
        "\r\n",
        "'''\r\n",
        "Ahora instanciamos lo que se utilizará como datos de entranmiento y le damos el directorio donde se encuentran\r\n",
        "las imagenes, teniendo en cuenta el train.datagen anterior que será el encargado de realizar el data augmentation\r\n",
        "'''\r\n",
        "train_generator = train_datagen.flow_from_directory(  \r\n",
        "    train_data_dir,                                             \r\n",
        "    target_size=(img_width, img_height),                            \r\n",
        "    batch_size=batch_size,                                      \r\n",
        "    shuffle = False,                                                               \r\n",
        "    class_mode='categorical')                                         \r\n",
        "\r\n",
        "'''\r\n",
        "Ahora instanciamos lo que se utilizará como datos de validación y le damos el directorio donde se encuentran\r\n",
        "las imagenes. Para este caso no se realiza el data augmentation, este se emplea en entrenamiento.\r\n",
        "'''\r\n",
        "\r\n",
        "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\r\n",
        "validation_generator = validation_datagen.flow_from_directory(  \r\n",
        "    validation_data_dir,\r\n",
        "    target_size=(img_width, img_height),\r\n",
        "    batch_size=batch_size, shuffle = False,\r\n",
        "    class_mode='categorical') \r\n",
        "\r\n",
        "\r\n",
        "'''\r\n",
        "Ahora instanciamos lo que se utilizará como datos de test y le damos el directorio donde se encuentran\r\n",
        "las imagenes. Para este caso no se realiza el data augmentation, este se emplea en entrenamiento.\r\n",
        "'''\r\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\r\n",
        "test_generator = test_datagen.flow_from_directory(  \r\n",
        "    test_data_dir,\r\n",
        "    target_size=(img_width, img_height), \r\n",
        "    batch_size=1,\r\n",
        "    shuffle = False,\r\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 864 images belonging to 6 classes.\n",
            "Found 216 images belonging to 6 classes.\n",
            "Found 120 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOf0oSchtafQ"
      },
      "source": [
        "# 3. Estructuracion y entrenamiento de red neuronal preentrenada:ResNet50\r\n",
        "\r\n",
        "Se va a utilizar la arquitectura de la red convolucional resnet50 de `keras`, para esto se configura capa de salida ajustada a nuestra necesidad de las clases. Adicionalmente se adicionan callbacks para el entrenamiento y toda la configuracion necesaria en el compilado, posteriormente se entrena."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UonWSMSgKRr9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf4445f-bd96-49e9-8f77-f2870d921424"
      },
      "source": [
        "'''\r\n",
        "Importamos la red neuronal resnet50 desde keras sin incluir la capa de salida,\r\n",
        "a continuacion añadimos la capa de salida propia que utilizara una funcion sigmoide\r\n",
        "para el problema de clasificacion binaria. \r\n",
        "'''\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "K.clear_session()\r\n",
        "\r\n",
        "# Instacia del modelo y configuración\r\n",
        "base_model = tf.keras.applications.resnet50.ResNet50(weights= 'imagenet', \r\n",
        "                                            include_top=False,              \r\n",
        "                                            input_shape= (64,64,3)) # Tamaño de imagenes\r\n",
        "\r\n",
        "x = base_model.output                                               \r\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)          # reduce dim del tensor                    \r\n",
        "x = tf.keras.layers.Dropout(0.5)(x)                      # regularizacion\r\n",
        "\r\n",
        "predictions = tf.keras.layers.Dense(6,                   # numero de clases           \r\n",
        "                    activation= 'softmax')(x)\r\n",
        "\r\n",
        "'''\r\n",
        "Unimos la capa de entrada que es resnet50 (o sus pesos) con la capa de salida diseñada anteriormente\r\n",
        "'''\r\n",
        "model = tf.keras.models.Model(inputs = base_model.input, \r\n",
        "                              outputs = predictions)\r\n",
        "\r\n",
        "\r\n",
        "'''\r\n",
        "Una vez construida construida la arquitectura de la red convolucional resnet50\r\n",
        "debemos compilar el modelo, en este paso definimos que función de perdida vamos a utilizar, que optimizador \r\n",
        "y que metricas queremos medir. Para esta modelación se utilizói lo siguiente\r\n",
        "\r\n",
        "--> Función de perdida (loss): categorical_crossentropy: La función de pérdida de crossentropía categorical se usa en decisiones con mas de dos clases.\r\n",
        "La pérdida le dice cuán equivocadas son las predicciones del modelo: https://keras.io/api/losses/probabilistic_losses/#categorical_crossentropy-function\r\n",
        "\r\n",
        "--> Optimizador: Adam con tasa de aprendizaje 0.0001: Adam es un método de descenso de gradiente estocástico que se basa en la estimación adaptativa de \r\n",
        "los momentos de primer y segundo orden: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\r\n",
        "\r\n",
        "--> Metrica: AUC: (Área bajo la curva) el cual mide  el “área o espacio” bajo la curva ROC y tiene por objeto medir la certeza de un modelo a la \r\n",
        "hora de realizar predicciones (toma valor de 1 cuándo se es 100% preciso) siendo invariable al umbral de clasificación.\r\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC\r\n",
        "'''\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy',                                      \r\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),         \r\n",
        "                metrics=[tf.keras.metrics.AUC()])                                                             \r\n",
        "\r\n",
        "# Observemos la arquitectura del modelo resnet50\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 70, 70, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 32, 32, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 32, 32, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 32, 32, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 34, 34, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 16, 16, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 16, 16, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 16, 16, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 16, 16, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 16, 16, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 16, 16, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 16, 16, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 16, 16, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 16, 16, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 16, 16, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 16, 16, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 16, 16, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 16, 16, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 16, 16, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 16, 16, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 16, 16, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 16, 16, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 8, 8, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 8, 8, 128)    0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 8, 8, 512)    131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 8, 8, 512)    0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 8, 8, 512)    0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 8, 8, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 8, 8, 128)    0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 8, 8, 512)    0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 8, 8, 512)    0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 8, 8, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 8, 8, 128)    0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 8, 8, 512)    0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 8, 8, 512)    0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 8, 8, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 8, 8, 128)    0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 8, 8, 512)    0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 8, 8, 512)    0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 4, 4, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 4, 4, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 4, 4, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 4, 4, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 4, 4, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 4, 4, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 4, 4, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 4, 4, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 4, 4, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 4, 4, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 4, 4, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 4, 4, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 4, 4, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 4, 4, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 4, 4, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 4, 4, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 4, 4, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 4, 4, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 4, 4, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 4, 4, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 4, 4, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 4, 4, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 4, 4, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 4, 4, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 4, 4, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 4, 4, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 2, 2, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 2, 2, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 2, 2, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 2, 2, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 2, 2, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 2, 2, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 2, 2, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 2, 2, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 2, 2, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 2, 2, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 2, 2, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 2, 2, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 6)            12294       dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,600,006\n",
            "Trainable params: 23,546,886\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSRdk14ZKtzY",
        "outputId": "9e4036fb-2f91-46ed-97ae-bfc0587fb8dd"
      },
      "source": [
        "'''\r\n",
        "Ahora se va a instanciar dos argumentos que nos van ayudar a prevenir overfitting\r\n",
        "por un lado el EarlyStopping que nos permite parar el entrenamiento si no observa mejoria en los entranamientos\r\n",
        "y el ModelCheckPoint que nos ayudara a guardar el mejor modelo de acuerdo a un argumento dado por el usuario\r\n",
        "'''\r\n",
        "\r\n",
        "\r\n",
        "keras_callbacks   = [\r\n",
        "      EarlyStopping(monitor='val_loss', patience=20, mode='min', min_delta=0.0001),\r\n",
        "      ModelCheckpoint('Bestmodel.h5', monitor='val_loss', save_best_only=True, mode='min')\r\n",
        "]\r\n",
        "\r\n",
        "'''\r\n",
        "Una vez tenemos lista la arquitectura, compilado y las funciones callbacks del modelo, procedemos a realiza el entrenamiento\r\n",
        " mediante el metodo fit_generator en donde se le define cuales son los datos de entrada, el numero de epocas (# numero de veces \r\n",
        "que la red pasa por los datos) y cuales son los datos de validacion\r\n",
        "'''\r\n",
        "historia = model.fit_generator(train_generator,                             \r\n",
        "                                  epochs=200,                            \r\n",
        "                                  validation_data=validation_generator,      \r\n",
        "                                  verbose=1,\r\n",
        "                                  workers=1,\r\n",
        "                                  callbacks=keras_callbacks,\r\n",
        "                                  use_multiprocessing = False) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "27/27 [==============================] - 11s 161ms/step - loss: 3.1690 - auc: 0.4577 - val_loss: 3.3669 - val_auc: 0.5065\n",
            "Epoch 2/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 2.7139 - auc: 0.5141 - val_loss: 2.6143 - val_auc: 0.5057\n",
            "Epoch 3/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 2.5916 - auc: 0.5285 - val_loss: 2.3179 - val_auc: 0.5026\n",
            "Epoch 4/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 2.4505 - auc: 0.5413 - val_loss: 2.0354 - val_auc: 0.5425\n",
            "Epoch 5/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 2.3733 - auc: 0.5610 - val_loss: 1.8363 - val_auc: 0.6062\n",
            "Epoch 6/200\n",
            "27/27 [==============================] - 3s 110ms/step - loss: 2.1932 - auc: 0.5752 - val_loss: 1.8850 - val_auc: 0.6168\n",
            "Epoch 7/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 2.0925 - auc: 0.5921 - val_loss: 1.8729 - val_auc: 0.6130\n",
            "Epoch 8/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 1.9935 - auc: 0.5968 - val_loss: 2.1713 - val_auc: 0.5744\n",
            "Epoch 9/200\n",
            "27/27 [==============================] - 3s 116ms/step - loss: 1.8638 - auc: 0.6523 - val_loss: 1.9476 - val_auc: 0.5932\n",
            "Epoch 10/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 1.8644 - auc: 0.6363 - val_loss: 1.6479 - val_auc: 0.6804\n",
            "Epoch 11/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 1.7269 - auc: 0.6683 - val_loss: 1.6119 - val_auc: 0.6902\n",
            "Epoch 12/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 1.6375 - auc: 0.7187 - val_loss: 1.6588 - val_auc: 0.6774\n",
            "Epoch 13/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 1.5442 - auc: 0.7453 - val_loss: 1.5336 - val_auc: 0.7365\n",
            "Epoch 14/200\n",
            "27/27 [==============================] - 3s 119ms/step - loss: 1.3865 - auc: 0.7988 - val_loss: 1.5014 - val_auc: 0.7518\n",
            "Epoch 15/200\n",
            "27/27 [==============================] - 3s 122ms/step - loss: 1.3297 - auc: 0.8195 - val_loss: 1.3747 - val_auc: 0.8080\n",
            "Epoch 16/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 1.0830 - auc: 0.8829 - val_loss: 1.5236 - val_auc: 0.7776\n",
            "Epoch 17/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 1.1439 - auc: 0.8834 - val_loss: 1.2961 - val_auc: 0.8467\n",
            "Epoch 18/200\n",
            "27/27 [==============================] - 3s 116ms/step - loss: 1.0374 - auc: 0.9039 - val_loss: 1.2431 - val_auc: 0.8560\n",
            "Epoch 19/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 0.8280 - auc: 0.9360 - val_loss: 1.1045 - val_auc: 0.9028\n",
            "Epoch 20/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 1.0520 - auc: 0.8972 - val_loss: 1.0104 - val_auc: 0.9310\n",
            "Epoch 21/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.8086 - auc: 0.9429 - val_loss: 0.9919 - val_auc: 0.9269\n",
            "Epoch 22/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 0.7656 - auc: 0.9490 - val_loss: 0.9428 - val_auc: 0.9400\n",
            "Epoch 23/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.7102 - auc: 0.9543 - val_loss: 1.0059 - val_auc: 0.9217\n",
            "Epoch 24/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.5998 - auc: 0.9652 - val_loss: 0.9811 - val_auc: 0.9341\n",
            "Epoch 25/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.6329 - auc: 0.9684 - val_loss: 0.8718 - val_auc: 0.9505\n",
            "Epoch 26/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.4476 - auc: 0.9839 - val_loss: 0.8196 - val_auc: 0.9596\n",
            "Epoch 27/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.5043 - auc: 0.9809 - val_loss: 0.7967 - val_auc: 0.9601\n",
            "Epoch 28/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.4446 - auc: 0.9833 - val_loss: 0.7435 - val_auc: 0.9725\n",
            "Epoch 29/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.3472 - auc: 0.9934 - val_loss: 0.7359 - val_auc: 0.9705\n",
            "Epoch 30/200\n",
            "27/27 [==============================] - 3s 116ms/step - loss: 0.3616 - auc: 0.9923 - val_loss: 0.6957 - val_auc: 0.9737\n",
            "Epoch 31/200\n",
            "27/27 [==============================] - 3s 120ms/step - loss: 0.2515 - auc: 0.9963 - val_loss: 0.6969 - val_auc: 0.9717\n",
            "Epoch 32/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 0.2812 - auc: 0.9939 - val_loss: 0.7144 - val_auc: 0.9713\n",
            "Epoch 33/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.2259 - auc: 0.9973 - val_loss: 0.7408 - val_auc: 0.9638\n",
            "Epoch 34/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.2011 - auc: 0.9981 - val_loss: 0.7348 - val_auc: 0.9679\n",
            "Epoch 35/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.2188 - auc: 0.9969 - val_loss: 0.7889 - val_auc: 0.9591\n",
            "Epoch 36/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.2308 - auc: 0.9971 - val_loss: 0.7324 - val_auc: 0.9676\n",
            "Epoch 37/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 0.1795 - auc: 0.9991 - val_loss: 0.7103 - val_auc: 0.9674\n",
            "Epoch 38/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 0.1784 - auc: 0.9979 - val_loss: 0.6928 - val_auc: 0.9649\n",
            "Epoch 39/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.1404 - auc: 0.9991 - val_loss: 0.6455 - val_auc: 0.9735\n",
            "Epoch 40/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.1496 - auc: 0.9988 - val_loss: 0.6386 - val_auc: 0.9711\n",
            "Epoch 41/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 0.1686 - auc: 0.9972 - val_loss: 0.6647 - val_auc: 0.9685\n",
            "Epoch 42/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.1534 - auc: 0.9981 - val_loss: 0.7427 - val_auc: 0.9545\n",
            "Epoch 43/200\n",
            "27/27 [==============================] - 3s 116ms/step - loss: 0.0931 - auc: 0.9999 - val_loss: 0.6636 - val_auc: 0.9696\n",
            "Epoch 44/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 0.0862 - auc: 0.9999 - val_loss: 0.6526 - val_auc: 0.9699\n",
            "Epoch 45/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0615 - auc: 1.0000 - val_loss: 0.6510 - val_auc: 0.9717\n",
            "Epoch 46/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.0492 - auc: 1.0000 - val_loss: 0.6185 - val_auc: 0.9756\n",
            "Epoch 47/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.0520 - auc: 1.0000 - val_loss: 0.6265 - val_auc: 0.9702\n",
            "Epoch 48/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0569 - auc: 0.9999 - val_loss: 0.5864 - val_auc: 0.9761\n",
            "Epoch 49/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.0386 - auc: 1.0000 - val_loss: 0.6040 - val_auc: 0.9751\n",
            "Epoch 50/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.0346 - auc: 1.0000 - val_loss: 0.6111 - val_auc: 0.9740\n",
            "Epoch 51/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0423 - auc: 1.0000 - val_loss: 0.6018 - val_auc: 0.9761\n",
            "Epoch 52/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0313 - auc: 1.0000 - val_loss: 0.6053 - val_auc: 0.9740\n",
            "Epoch 53/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0383 - auc: 1.0000 - val_loss: 0.5955 - val_auc: 0.9741\n",
            "Epoch 54/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.0400 - auc: 1.0000 - val_loss: 0.5846 - val_auc: 0.9748\n",
            "Epoch 55/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 0.0230 - auc: 1.0000 - val_loss: 0.5696 - val_auc: 0.9764\n",
            "Epoch 56/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0306 - auc: 1.0000 - val_loss: 0.5357 - val_auc: 0.9813\n",
            "Epoch 57/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0275 - auc: 1.0000 - val_loss: 0.5587 - val_auc: 0.9771\n",
            "Epoch 58/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.0271 - auc: 0.9998 - val_loss: 0.5516 - val_auc: 0.9794\n",
            "Epoch 59/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0193 - auc: 1.0000 - val_loss: 0.5573 - val_auc: 0.9772\n",
            "Epoch 60/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.0183 - auc: 1.0000 - val_loss: 0.5560 - val_auc: 0.9767\n",
            "Epoch 61/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.0284 - auc: 1.0000 - val_loss: 0.6364 - val_auc: 0.9655\n",
            "Epoch 62/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0160 - auc: 1.0000 - val_loss: 0.5533 - val_auc: 0.9781\n",
            "Epoch 63/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0131 - auc: 1.0000 - val_loss: 0.5349 - val_auc: 0.9795\n",
            "Epoch 64/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0191 - auc: 1.0000 - val_loss: 0.5110 - val_auc: 0.9815\n",
            "Epoch 65/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 0.0109 - auc: 1.0000 - val_loss: 0.5291 - val_auc: 0.9795\n",
            "Epoch 66/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0223 - auc: 1.0000 - val_loss: 0.5193 - val_auc: 0.9797\n",
            "Epoch 67/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0148 - auc: 1.0000 - val_loss: 0.5243 - val_auc: 0.9810\n",
            "Epoch 68/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.0119 - auc: 1.0000 - val_loss: 0.5194 - val_auc: 0.9811\n",
            "Epoch 69/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0166 - auc: 1.0000 - val_loss: 0.5298 - val_auc: 0.9789\n",
            "Epoch 70/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0143 - auc: 1.0000 - val_loss: 0.5134 - val_auc: 0.9800\n",
            "Epoch 71/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.0134 - auc: 1.0000 - val_loss: 0.5121 - val_auc: 0.9802\n",
            "Epoch 72/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0140 - auc: 1.0000 - val_loss: 0.5097 - val_auc: 0.9786\n",
            "Epoch 73/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.0129 - auc: 1.0000 - val_loss: 0.5117 - val_auc: 0.9799\n",
            "Epoch 74/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0108 - auc: 1.0000 - val_loss: 0.5650 - val_auc: 0.9723\n",
            "Epoch 75/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0179 - auc: 1.0000 - val_loss: 0.5364 - val_auc: 0.9775\n",
            "Epoch 76/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0087 - auc: 1.0000 - val_loss: 0.5103 - val_auc: 0.9800\n",
            "Epoch 77/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.0083 - auc: 1.0000 - val_loss: 0.4982 - val_auc: 0.9808\n",
            "Epoch 78/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.0061 - auc: 1.0000 - val_loss: 0.5137 - val_auc: 0.9793\n",
            "Epoch 79/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0080 - auc: 1.0000 - val_loss: 0.5216 - val_auc: 0.9776\n",
            "Epoch 80/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0094 - auc: 1.0000 - val_loss: 0.5261 - val_auc: 0.9779\n",
            "Epoch 81/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 0.0082 - auc: 1.0000 - val_loss: 0.5105 - val_auc: 0.9778\n",
            "Epoch 82/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0075 - auc: 1.0000 - val_loss: 0.4915 - val_auc: 0.9807\n",
            "Epoch 83/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0066 - auc: 1.0000 - val_loss: 0.4936 - val_auc: 0.9794\n",
            "Epoch 84/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 0.0144 - auc: 1.0000 - val_loss: 0.4825 - val_auc: 0.9817\n",
            "Epoch 85/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.0181 - auc: 1.0000 - val_loss: 0.4976 - val_auc: 0.9811\n",
            "Epoch 86/200\n",
            "27/27 [==============================] - 3s 110ms/step - loss: 0.0084 - auc: 1.0000 - val_loss: 0.5108 - val_auc: 0.9791\n",
            "Epoch 87/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.0100 - auc: 1.0000 - val_loss: 0.4833 - val_auc: 0.9832\n",
            "Epoch 88/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0074 - auc: 1.0000 - val_loss: 0.4839 - val_auc: 0.9822\n",
            "Epoch 89/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.0050 - auc: 1.0000 - val_loss: 0.5052 - val_auc: 0.9809\n",
            "Epoch 90/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0043 - auc: 1.0000 - val_loss: 0.4874 - val_auc: 0.9819\n",
            "Epoch 91/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.0052 - auc: 1.0000 - val_loss: 0.4770 - val_auc: 0.9825\n",
            "Epoch 92/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0078 - auc: 1.0000 - val_loss: 0.4563 - val_auc: 0.9842\n",
            "Epoch 93/200\n",
            "27/27 [==============================] - 3s 110ms/step - loss: 0.0050 - auc: 1.0000 - val_loss: 0.4583 - val_auc: 0.9853\n",
            "Epoch 94/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.0047 - auc: 1.0000 - val_loss: 0.4550 - val_auc: 0.9858\n",
            "Epoch 95/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0044 - auc: 1.0000 - val_loss: 0.4666 - val_auc: 0.9839\n",
            "Epoch 96/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.0059 - auc: 1.0000 - val_loss: 0.4953 - val_auc: 0.9797\n",
            "Epoch 97/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0050 - auc: 1.0000 - val_loss: 0.4827 - val_auc: 0.9809\n",
            "Epoch 98/200\n",
            "27/27 [==============================] - 3s 116ms/step - loss: 0.0036 - auc: 1.0000 - val_loss: 0.4644 - val_auc: 0.9831\n",
            "Epoch 99/200\n",
            "27/27 [==============================] - 3s 117ms/step - loss: 0.0039 - auc: 1.0000 - val_loss: 0.4471 - val_auc: 0.9848\n",
            "Epoch 100/200\n",
            "27/27 [==============================] - 3s 120ms/step - loss: 0.0065 - auc: 1.0000 - val_loss: 0.4425 - val_auc: 0.9850\n",
            "Epoch 101/200\n",
            "27/27 [==============================] - 3s 118ms/step - loss: 0.0030 - auc: 1.0000 - val_loss: 0.4339 - val_auc: 0.9866\n",
            "Epoch 102/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.0035 - auc: 1.0000 - val_loss: 0.4346 - val_auc: 0.9867\n",
            "Epoch 103/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0025 - auc: 1.0000 - val_loss: 0.4377 - val_auc: 0.9863\n",
            "Epoch 104/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.0025 - auc: 1.0000 - val_loss: 0.4409 - val_auc: 0.9873\n",
            "Epoch 105/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0043 - auc: 1.0000 - val_loss: 0.4553 - val_auc: 0.9856\n",
            "Epoch 106/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0025 - auc: 1.0000 - val_loss: 0.4510 - val_auc: 0.9858\n",
            "Epoch 107/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.0043 - auc: 1.0000 - val_loss: 0.4724 - val_auc: 0.9828\n",
            "Epoch 108/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0039 - auc: 1.0000 - val_loss: 0.5381 - val_auc: 0.9738\n",
            "Epoch 109/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.0022 - auc: 1.0000 - val_loss: 0.5334 - val_auc: 0.9738\n",
            "Epoch 110/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0027 - auc: 1.0000 - val_loss: 0.5139 - val_auc: 0.9771\n",
            "Epoch 111/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.0054 - auc: 1.0000 - val_loss: 0.4955 - val_auc: 0.9787\n",
            "Epoch 112/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 0.0030 - auc: 1.0000 - val_loss: 0.4998 - val_auc: 0.9787\n",
            "Epoch 113/200\n",
            "27/27 [==============================] - 3s 112ms/step - loss: 0.0024 - auc: 1.0000 - val_loss: 0.4951 - val_auc: 0.9794\n",
            "Epoch 114/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 0.0028 - auc: 1.0000 - val_loss: 0.4734 - val_auc: 0.9818\n",
            "Epoch 115/200\n",
            "27/27 [==============================] - 3s 115ms/step - loss: 0.0020 - auc: 1.0000 - val_loss: 0.4846 - val_auc: 0.9807\n",
            "Epoch 116/200\n",
            "27/27 [==============================] - 3s 113ms/step - loss: 0.0018 - auc: 1.0000 - val_loss: 0.4981 - val_auc: 0.9793\n",
            "Epoch 117/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.0021 - auc: 1.0000 - val_loss: 0.5056 - val_auc: 0.9783\n",
            "Epoch 118/200\n",
            "27/27 [==============================] - 3s 114ms/step - loss: 0.0018 - auc: 1.0000 - val_loss: 0.5074 - val_auc: 0.9774\n",
            "Epoch 119/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.0034 - auc: 1.0000 - val_loss: 0.5130 - val_auc: 0.9773\n",
            "Epoch 120/200\n",
            "27/27 [==============================] - 3s 110ms/step - loss: 0.0024 - auc: 1.0000 - val_loss: 0.5097 - val_auc: 0.9762\n",
            "Epoch 121/200\n",
            "27/27 [==============================] - 3s 111ms/step - loss: 0.0047 - auc: 1.0000 - val_loss: 0.4821 - val_auc: 0.9798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZctDutdt8cV"
      },
      "source": [
        "# 4. Graficas de desempeño del entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "4eP2qDGbpjUp",
        "outputId": "297ecf1e-dddc-47a3-f8c8-cf3468b61224"
      },
      "source": [
        "'''\r\n",
        "Para evaluar como ha sido el desempeño del modelo realizamos un par de graficos\r\n",
        "que nos muestran como se comporto la metrica AUC, tanto del conjunto de entrenamiento\r\n",
        "como de validacion, durante las epocas en que se entreno el modelo.\r\n",
        "\r\n",
        "Como segunda grafica observamos el comportamiento de la funcion de costo, al igual que el \r\n",
        "auc, para train y validacion durante todas las epocas\r\n",
        "'''\r\n",
        "# Grafica 1: Comportamiento desempeño AUC \r\n",
        "plt.plot(historia.history['auc'])\r\n",
        "plt.plot(historia.history['val_auc'])\r\n",
        "plt.title('model auc')\r\n",
        "plt.ylabel('auc')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'validation'], loc='upper left')\r\n",
        "plt.grid()\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Grafica 2: Comportamiento funcion de perdida\r\n",
        "plt.plot(historia.history['loss'])\r\n",
        "plt.plot(historia.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'validation'], loc='upper left')\r\n",
        "plt.grid()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOCmQ2SPuAMn"
      },
      "source": [
        "# 5. Prueba de desempeño en los datos de testeo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJTxf6Gdj2as",
        "outputId": "20ee3943-7432-4e89-fb46-acc89ca9dfe4"
      },
      "source": [
        "'''\r\n",
        "Ahora vamos a realizar las predicciones para los datos de test y observemos como se comporta\r\n",
        "el modelo en terminos de funcion de perdida y desempeño\r\n",
        "'''\r\n",
        "filenames = test_generator.filenames\r\n",
        "nb_samples = len(filenames)\r\n",
        "\r\n",
        "predict = model.predict_generator(test_generator,steps = nb_samples,workers=0)\r\n",
        "\r\n",
        "loss, acc = model.evaluate_generator(test_generator, steps=nb_samples, verbose=0)\r\n",
        "loss, acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4506300687789917, 0.9836388826370239)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}